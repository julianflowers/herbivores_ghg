---
title: "Herbivory coding"
format: html
editor: visual
execute: 
  cache: false
  message: false
  warning: false
  echo: false
toc: true
toc-location: left
code-fold: true
code-tools: true
---

## Import and wrangle data

```{r}
#| label: import data 
## load libraries

library(pacman)
pacman::p_load(tidyverse, readxl, here, skimr, overviewR, ggmap)       ## readxl is needed to load excel files into R
                                              ## the `here` package helps with file paths


path <- here::here("data")

xls <- list.files(path, "xls", full.names = TRUE)

data <- readxl::read_xlsx(xls[2])

data <- data |>
  janitor::clean_names()

```

Lets look at the data

```{r}
#| label: descriptives
nrow <- nrow(data)
ncol <- ncol(data)

skimr::skim(data)
```

-   The data set has `r nrow` rows and `r ncol` columns

```{r}

data |>
  count(europe, sort = TRUE)
```

## Mapping

To map locations of studies we need to

1.  Extract the lat longs
2.  Convert them to decimal coordinates

Lets look at the different ways in which lat-longs are recorded in the data so we can create string patterns to extract and convert the values.

The basic pattern is degrees and minutes, some have seconds - this can be represented as 1-2 digits followed by a variable number of non-digits repeated 2 or 3 times and with a compass point at the beginning or the end.

Looking at the unique contents of the `latitude_n_s` field we can also see it contains non lats (a DOI) and also other numbers which we need to remove or exclude.

The data is very messy - full of extraneous characters and extra text.

Let's start simple - we'll extract a list of coordinates from `latitude_n_s` and `longitude_e_w` try simple patterns

-   \\d{1,2}.\*\[NSEW\] find a string which has 1 or 2 digits followed by any number of other characters and then a capital N, S, E or W
-   \[NSEW\].\*\\d{1,2} as above but digits follow N, S, E, W

```{r}
#| label: pattern matching

data_1 <- data |>
  select(refs = item, latitude_n_s, longitude_e_w) |>
  mutate(lats = str_extract_all(latitude_n_s, paste0("\\d{1,2}.*[NSEW]", "|", "[NSEW].*\\d{1,2}")))
  
data_1 <- data_1 |>
  mutate(longs = str_extract_all(longitude_e_w, paste0("\\d{1,2}.*[NSEW]", "|", "[NSEW].*\\d{1,2}")))
  
data_1 |>
  gt::gt()
```

There are some issues here:

-   Extraneous text e.g '20 sites between 6Â° 32â€² W'

-   Extraneous numbers e.g. 1: 55.87Â° N

Let's try and fix these - we can clean extraneous text and numbers.

```{r}

data_2 <- data_1 |>
  mutate_all(~str_remove(., "20 sites")) |>
  mutate_all( ~str_remove(., "\\r\\nCOMPARATOR SITE")) |>
  mutate_all(~str_remove(., "latitude")) |>
  mutate_all(~str_remove_all(., "\\d{1}:\\s")) |>
  mutate_all(~str_remove(., "EXPOSURE SITE.*:")) |>
  #mutate_all(~str_remove(., "-Latitude (state in info)")) |>
  mutate_all(~str_remove(., "\\r\\n")) |>
  mutate_all(~str_remove(., "NY.\\d{6}"))


data_2
 
```

We can use these patterns to isolate the lat-longs, extract the numerical data and calculate the decimal coordinates.

```{r}
#| label: dry run

geo_data <- data_2 |>
  select(refs, lats, longs) |>
  mutate(lat_point = str_extract(lats, "^[NS]|[NS]$"), 
         long_point = str_extract(longs, "^[EW]|[EW]$"))   ## get compass information
```

```{r}

## identify already decimal coordinates
geo_data <- geo_data |>
  mutate(lat_cat = str_match(lats, "\\d{1,2}\\.\\d{1,2}"), 
         long_cat = str_match(longs, "\\d{1,2}\\.\\d{1,2}")) 

## identify [NSEW]deg:min:sec pattern

geo_data <- geo_data |>
  mutate(lat_cat = ifelse(is.na(lat_cat), str_extract(lats, "[NS]\\d{1,2}:\\d{1,2}:\\d{1,2}"), lat_cat), 
         long_cat = ifelse(is.na(long_cat), str_extract(longs, "[EW]\\d{1,2}:\\d{1,2}:\\d{1,2}"), long_cat), 
         lat_point = ifelse(is.na(lat_point), str_extract(lat_cat, "[NS]"), lat_point),
         long_point = ifelse(is.na(long_point), str_extract(long_cat, "[EW]"), long_point))

geo_data 
```

```{r}
geo_data <- geo_data |>
  mutate(lat_degrees = str_extract(lats, "\\d{1,2}"), ## first numbers
         long_degrees = str_extract(longs, "\\d{1,2}"), 
         lat_mins = str_extract_all(lats, "\\d{1,2}")) |>
  unnest_wider("lat_mins") |>
  mutate(long_mins = str_extract_all(longs, "\\d{1,2}")) |>
  unnest_wider("long_mins", names_repair = "unique") |>
  mutate_at(.vars = 8:21, as.numeric) |>
  select(refs, lat_point, long_point, lat_cat, long_cat, ...10, ...11, ...16, ...17) |>
  group_by(refs, lat_point, long_point ) |>
  summarise(dec_lat = ifelse(is.na(lat_cat), ...10 + ...11/60, ...10 + ...11/100), 
         dec_long = ifelse(is.na(long_cat), ...16 + ...17/60, ...16 + ...17/100), 
         dec_long = ifelse(long_point == "W", -dec_long, dec_long)) |>
  select(refs, dec_lat, dec_long) |>
  distinct()

geo_data

```

```{r}
library(sf)

coords <- geo_data |>
  drop_na() |>
  st_as_sf(coords = c(x = "dec_long", y = "dec_lat"), crs = 4326)
  
coords <- coords |>
  left_join(data, by = c("refs" = "item"))
```

## Interactive map

```{r}
library(mapview);library(sp);library(ggspatial);library(leaflet);library(leafpop)

mapview(coords, legend = FALSE, popup = popupTable(coords, zcol = c("refs", "herbivore_species_or_simulation_exposure")))
```

## Static map

```{r}

coords |>
  ggplot() +
  annotation_map_tile("cartolight") +
  geom_sf() +
  coord_sf() +
  theme_void()
  

```
